{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7rpHaCo/EUcy2v7vBR0Zk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/singhayushh/EC881--Assignment/blob/linux/DiabeticRetinopathy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "\n",
        "The goal is to make a highly accurate diabetic retinopathy model by using different CNN architectures (viz. MobileNet, EfficientNet, Inception V3 and ResNet) for a comparative study and push the best working model to deployment for live usage of the AI for actual patient images in various medicinal institutes.\n",
        "\n",
        "The model can be massively improved with:\n",
        "\n",
        "- high-resolution images\n",
        "- better data sampling\n",
        "- ensuring there is no leaking between training and validation sets.\n",
        "- better target variable (age) normalization\n",
        "- pretrained models\n",
        "- attention/related techniques to focus on areas\n",
        "\n",
        "************\n",
        "\n",
        "### Authors\n",
        "\n",
        "- [Ayush Singh](https://github.com/singhayushh)\n",
        "- [Agni Sain](https://linkedin.com/in/)\n",
        "- [Mayukh Sen](https://linkedin.com/in/)\n",
        "- [Aryan Shaw](https://linkedin.com/in/)\n",
        "\n",
        "************\n",
        "\n",
        "### The Model\n",
        "\n",
        "The model we create will be run through four different CNN architectures:\n",
        "- MobileNet v3\n",
        "- Inception v3\n",
        "- ResNet\n",
        "- EfficientNet\n",
        "\n",
        "All four will be trained and tested on the same data and based on the output, the most accurate model will be used in the live production environment.\n"
      ],
      "metadata": {
        "id": "Gj_hEf85TaBn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Download Data\n",
        "\n",
        "#### 1.1. Download kaggle.json\n",
        "\n",
        "We start by uploading the kaggle.json in order to use datasets from kaggle. This json file can be download from Account > API section of your kaggle profile."
      ],
      "metadata": {
        "id": "uiY4jKa3ae58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install kaggle cli\n",
        "!pip install kaggle\n",
        "\n",
        "# download kaggle.json from user prompt\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "-L8g6Pw5aSLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2. Create ~/.kaggle dir\n",
        "\n",
        "Create a new ~/.kaggle directory at the project root. We also need to move the kaggle.json to ~/.kaggle"
      ],
      "metadata": {
        "id": "3JFSYoHbbgNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create .kaggle directory at root to save kaggle.json\n",
        "!mkdir ~/.kaggle\n",
        "\n",
        "# move downloaded kaggle.json to the new directory\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "\n",
        "# allow execute permissions\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "XYHW6e4EbfXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3. Download dataset\n",
        "\n",
        "In this step, we will download the 'diabetic-retinopathy-detection` dataset from as well as extract its zip contents to train and test directories."
      ],
      "metadata": {
        "id": "vre3kO__cugA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download dataset from kaggle cli\n",
        "!kaggle competitions download -c 'diabetic-retinopathy-detection'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojg_xQrQc9AB",
        "outputId": "ed914762-4057-47a9-997e-8afc591282c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading diabetic-retinopathy-detection.zip to /content\n",
            "100% 82.2G/82.2G [06:38<00:00, 228MB/s]\n",
            "100% 82.2G/82.2G [06:38<00:00, 222MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the dataset\n",
        "!7za x 'diabetic-retinopathy-detection.zip'\n",
        "\n",
        "# Create train and test directories\n",
        "!mkdir train\n",
        "!mkdir test\n",
        "\n",
        "# Move ZIP files to their directories\n",
        "!mv train.* train\n",
        "!mv test.* test\n",
        "\n",
        "# Extract data\n",
        "!7za x train.zip.001\n",
        "!7za x test.zip.001"
      ],
      "metadata": {
        "id": "wee2BNfldYyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Image Preprocessing\n",
        "\n",
        "#### 2.1. Crop and Resize\n",
        "\n",
        "All images were scaled down to 256 by 256. Despite taking longer to train, the detail present in photos of this size is much greater then at 128 by 128."
      ],
      "metadata": {
        "id": "4Ws5xCylsIqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# package imports\n",
        "import os\n",
        "import sys\n",
        "from PIL import ImageFile\n",
        "from skimage import io\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "# utility function to create directory with given name if absent\n",
        "def create_directory(directory):\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "# crop and resize given image and save to new path\n",
        "def crop_and_resize_images(path, new_path, cropx, cropy, img_size=256):\n",
        "    create_directory(new_path)\n",
        "    dirs = [l for l in os.listdir(path) if l != '.DS_Store']\n",
        "    total = 0\n",
        "    for item in dirs:\n",
        "        img = io.imread(path+item)\n",
        "        y,x,channel = img.shape\n",
        "        startx = x//2-(cropx//2)\n",
        "        starty = y//2-(cropy//2)\n",
        "        img = img[starty:starty+cropy,startx:startx+cropx]\n",
        "        img = resize(img, (256,256))\n",
        "        io.imsave(str(new_path + item), img)\n",
        "        total += 1\n",
        "        print(\"Saving: \", item, total)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    crop_and_resize_images(path='/content/train/', new_path='/content/train-resized-256/', cropx=1800, cropy=1800, img_size=256)\n",
        "    crop_and_resize_images(path='/content/test/', new_path='/content/test-resized-256/', cropx=1800, cropy=1800, img_size=256)"
      ],
      "metadata": {
        "id": "5m5Nzp-Ms15c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2. Training data pruning\n",
        "\n",
        "Scikit-Image raised multiple warnings during resizing, due to these images having no color space. Because of this, any images that were completely black were removed from the training data."
      ],
      "metadata": {
        "id": "hAhbAEPWtoBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# package imports\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "# create a 'image' named column with non-black images\n",
        "def find_black_images(file_path, df):\n",
        "    lst_imgs = [l for l in df['image']]\n",
        "    return [1 if np.mean(np.array(Image.open(file_path + img))) == 0 else 0 for img in lst_imgs]\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    start_time = time.time()\n",
        "    trainLabels = pd.read_csv('/content/labels/trainLabels.csv')\n",
        "\n",
        "    trainLabels['image'] = [i + '.jpeg' for i in trainLabels['image']]\n",
        "    trainLabels['black'] = np.nan\n",
        "\n",
        "    trainLabels['black'] = find_black_images('/content/train-resized-256/', trainLabels)\n",
        "    trainLabels = trainLabels.loc[trainLabels['black'] == 0]\n",
        "    trainLabels.to_csv('trainLabels_master.csv', index=False, header=True)\n",
        "\n",
        "    print(\"Completed\")\n",
        "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "id": "vvmfzlDHy6SE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.3. Image Rotation\n",
        "\n",
        "In order to reduce noise from the images, all images were rotated and mirrored."
      ],
      "metadata": {
        "id": "QU18Hojoz7Cg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# packages import\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from skimage.transform import rotate\n",
        "from cv2 import cv2\n",
        "import os\n",
        "import time\n",
        "\n",
        "def rotate_images(file_path, degrees_of_rotation, lst_imgs):\n",
        "    for l in lst_imgs:\n",
        "        img = io.imread(file_path + str(l) + '.jpeg')\n",
        "        img = rotate(img, degrees_of_rotation)\n",
        "        io.imsave(file_path + str(l) + '_' + str(degrees_of_rotation) + '.jpeg', img)\n",
        "\n",
        "\n",
        "def mirror_images(file_path, mirror_direction, lst_imgs):\n",
        "    for l in lst_imgs:\n",
        "        img = cv2.imread(file_path + str(l) + '.jpeg')\n",
        "        img = cv2.flip(img, 1)\n",
        "        cv2.imwrite(file_path + str(l) + '_mir' + '.jpeg', img)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    start_time = time.time()\n",
        "    trainLabels = pd.read_csv(\"/content/labels/trainLabels_master.csv\")\n",
        "\n",
        "    trainLabels['image'] = trainLabels['image'].str.rstrip('.jpeg')\n",
        "    trainLabels_no_DR = trainLabels[trainLabels['level'] == 0]\n",
        "    trainLabels_DR = trainLabels[trainLabels['level'] >= 1]\n",
        "\n",
        "    lst_imgs_no_DR = [i for i in trainLabels_no_DR['image']]\n",
        "    lst_imgs_DR = [i for i in trainLabels_DR['image']]\n",
        "\n",
        "    # Mirror Images with no DR one time\n",
        "    print(\"Mirroring Non-DR Images\")\n",
        "    mirror_images('/content/train-resized-256/', 1, lst_imgs_no_DR)\n",
        "\n",
        "\n",
        "    # Rotate all images that have any level of DR\n",
        "    print(\"Rotating 90 Degrees\")\n",
        "    rotate_images('/content/train-resized-256/', 90, lst_imgs_DR)\n",
        "\n",
        "    print(\"Rotating 120 Degrees\")\n",
        "    rotate_images('/content/train-resized-256/', 120, lst_imgs_DR)\n",
        "\n",
        "    print(\"Rotating 180 Degrees\")\n",
        "    rotate_images('/content/train-resized-256/', 180, lst_imgs_DR)\n",
        "\n",
        "    print(\"Rotating 270 Degrees\")\n",
        "    rotate_images('/content/train-resized-256/', 270, lst_imgs_DR)\n",
        "\n",
        "    print(\"Mirroring DR Images\")\n",
        "    mirror_images('/content/train-resized-256/', 0, lst_imgs_DR)\n",
        "\n",
        "    print(\"Completed\")\n",
        "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "id": "VkQtpDRb0SHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W2eZoHGGlmx7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}